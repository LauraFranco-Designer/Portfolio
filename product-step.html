<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title> Next Step </title>
	<link rel="stylesheet" href="project-product-step.css">
		<!-- Linking Font Awsome for icons -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.1/css/all.min.css">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="about me-style.css">
	<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
	<link rel="icon" href="risorse/logo_laurafranco.png" type="image/png">

</head>
<body>

<button class="go-top-btn">
	<img src="risorse/arrow_up.png" alt="arrow up">
</button>

<a href="index.html#projects" class="go-back-btn">
    <img src="risorse/arrow_back1.png" alt="arrow left">
</a>



<!-- Header / Navbar -->
	<header>
		<nav class="navbar section-content">
			<a href="#home" class="nav-logo">
				<h2 class="logo-text"> LAURA FRANCO</h2>
			</a>
			<ul class="nav-menu">
				<button id="menu-close-button" class="fas fa-times"></button>
				<li class="nav-item">
					<a href="index.html" class="nav-link">Home</a>
				</li>	
				<li class="nav-item">
					<a href="about me.html" class="nav-link">About Me</a>
				</li>	
				<li class="nav-item">
					<a href="index.html#projects" class="nav-link">Projects</a>
				</li>
				<li class="nav-item">
					<a href="index.html#contacts" class="nav-link">Contacts</a>
				</li>
			</ul>

			<button id="menu-open-button" class="fas fa-bars"></button>
		</nav>
	</header>


<a href=""><img src="" style="position: fixed; right: 0; top: 10%; width: 70px;"> </a>

	<main>
		<!-- Hero section -->
		<section class="hero-section" id="step-project">
			<div class="section-content">
				<div class="hero-details">
					<h2 class="title">Let them know your next STEP</h2>
					<h1 class="subtitle">A research on human-phone interaction</h1>
					<p class="concept">Most people in the city center tend to use their phones while moving around. Some actively use them for calls, messages, social media, or navigation, while others simply hold them in their hands. Often, the device creates a kind of bubble that dulls users' awareness of their surroundings. This detachment from the environment can lead to potentially dangerous situations, both for the phone users and the people around them.
When using a phone, the norms that govern social interaction shift in a way that makes it harder to interpret others’ intentions, especially their movements or next steps. This creates confusion among other pedestrians, who struggle to read social cues and therefore cannot respond appropriately.</p>
				</div>
				<div class="hero-image-wrapper">
					<img src="risorse/step_long.png" class="hero-image"></img>
					<p class="brief"> 
					The design aims to restore a sense of balance among pedestrians using their phones by helping them become more aware of their surroundings and less absorbed in their screen-based tasks. Following an initial exploratory phase, focused on understanding current interaction patterns and defining the desired ones, a series of usability tests were conducted to refine the final concept. This concept was then prototyped, tested, and evaluated to assess whether it could support the intended interaction dynamics.
				</div>
			</div>
		</section>

<!-- Research section -->
		<section class="research-section" id="research">
			<h2 class="section-title">Research Process</h2>
			<div class="section-content">
				<div class="research-details1">
					<p class="text"> Philosophy explored the dualism between mind and body. The Cartesian split theory shows 
						us that the mind can be considered the software that runs on the body, which is the hardware 
						(the mind explains behaviour while the body is the output device). Mind and body should be 
						perfectly balanced to consent us to move and act optimally in the environment but sometimes 
						this is not the case. 
						With the use of smartphones we tend to live in 
						two different dimensions, our minds, and thoughts are not aligned with our actions. We receive 
						dozens and dozens of messages, calls, e-mails, pictures, and much more. We are constantly 
						and instantly connected with people around us or even around the world. But often we lose 
						connection with what is happening around us.
 					</p>	
					<img src="risorse/balance.png" class="research-image_balance">
					
					<p class="text"> Multiple research activities were conducted to develop a comprehensive understanding of the scenario and its interactions. Each activity is only briefly summarized here but explained in detail in the <a href="risorse/step/research activities.pdf" class="button full-report" target="_blank">report - reserch activities section</a>
 					</p>	
					<img src="risorse/current_scenario.png" class="research-image_scenario">
				</div>

				<div class="section-container">

					<ul class="tasks-list">				
						<li class="tasks">
							<img src="risorse/step/casual observation.png" class="task-image">
							<h3 class="task-title">Casual Observation</h3>
							<p class="description">To gain an overview of the selected context as external observer</p>
						</li>
						<li class="tasks">
							<img src="risorse/step/desk research.png" class="task-image">
							<h3 class="task-title">Desk Research</h3>
							<p class="description">To get inspired by other people’s research & papers. To check what is already known 
								about this topic and make connections between different fields</p>
						</li>
						<li class="tasks">
							<img src="risorse/step/survey&interview.png" class="task-image">
							<h3 class="task-title">Survey & Interview</h3>
							<p class="description">To understand people's experiences, needs, thoughts, and feelings through both structured surveys and open, flexible discussions</p>
						</li>
						<li class="tasks">
							<img src="risorse/step/roleplay.png" class="task-image">
							<h3 class="task-title">Roleplay</h3>
							<p class="description">To show trends in people’s behavior when walking and using / not using the phone in a crowded environment</p>
						</li>
						<li class="tasks">
							<img src="risorse/step/ethnography.png" class="task-image">
							<h3 class="task-title">Ethnography</h3>
							<p class="description">To take into account the smartphone point of view</p>
						</li>
						<li class="tasks">
							<img src="risorse/step/sensitising activity.png" class="task-image">
							<h3 class="task-title">Sensitising Activity</h3>
							<p class="description">To gain some extra insights into user’s needs through the generative and making 
								technique</p>
						</li>
					</ul>
						
				</div>
			</div>
		</section>

<!-- Insights section -->
		<section class="insights-section" id="test">
			<h2 class="section-title">Key Insights</h2>
			<div class="section-content">
				<div class="insights-details1">
					<p class="text">The research activities led to several valuable insights and reflections, including the surprising similarities between the experiences of blind individuals and those of people using their phones while walking. Additionally, phone users often rely on their peripheral vision to gather information about their surroundings, but this is typically insufficient for confident navigation. As a result, they tend to follow and rely on the guidance of the person walking in front of them.</p>	
					<img src="risorse/insights_step1.png" class="insights-image1">

					<p class="text">The more attention a task on the phone demands, the less cognitive capacity is available to process the surrounding environment, causing users to overlook important details and spatial cues.
Another noteworthy observation is that the angle of the phone consistently aligns with the direction of the user's toes, even when they move in a zigzag pattern.
Furthermore, when using a phone, the walking path becomes inconsistent and unpredictable.</p>	
					<img src="risorse/insights_step2.png" class="insights-image2">				
				</div>
			</div>
		</section>

<!-- Design Goal -->
		<section class="designgoal-section" id="test">
			<h2 class="section-title">Design Goal</h2>
			<div class="section-content">
				<div class="designgoal-details1">
					<p class="text">Design a mobile-integrated device that enables implicit, non-disruptive communication of pedestrian movement intent between individuals using their phones in crowded environments, to enhance safety, awareness, and flow without requiring direct attention or verbal interaction.</p>
				</div>
			</div>
		</section>

<!-- Concept section -->
		<section class="concept-section" id="test">
			<h2 class="section-title">Concept definition</h2>
			<div class="section-content">
				<div class="concept-details1">
					<p class="text">After testing various <a href="risorse/step/lowfidelity prototype.pdf" class="button full-report" target="_blank">low-fidelity prototypes</a> to determine a final design direction, the concept takes the form of an accessory that can be attached to any smartphone case. This design enables users to perform different actions using multiple fingers simultaneously. The challenge of this interactive "game" lies in the fact that users must coordinate finger movements that mirror their gait and spatial movement. At the same time, the visible gadget on the phone cover signals to others nearby that the user is making an effort to stay aware of their surroundings.</p>	
					<ul class="tasks-list">				
						<li class="tasks">
							<p class="description">Current Interaction</p>
							<img src="risorse/step/current_situation.png" class="task-image"></li>
							<li class="tasks">
							<p class="description">Desired Interaction</p>
							<img src="risorse/step/desired_situation.png" class="task-image"></li>
					</ul>	
					<p class="text">A series of prototypes were developed to explore and replicate the desired interaction through various approaches. Each prototype was tested with potential users and evaluated to gather valuable insights. For a more detailed description of each prototype,  refer to the <a href="risorse/step/highfe prototype.pdf" class="button full-report" target="_blank">prototype section</a> of the report. The insights collected from testing have been translated into product requirements, which are summarized in the final concept.</p>

				</div>
			</div>
		</section>


					<!-- Design intended use -->
		<section class="designgoal-section" id="test">
			<h2 class="section-title">Intended Use</h2>
			<div class="section-content">
				<div class="designgoal-details1">
					<p class="text">When users intend to turn left or right, they simply squeeze the corresponding side of the device with the palm of their hand. This action activates a light on that side. Thanks to the soft, responsive material of the device, this gesture is intuitive and effortless. The design not only triggers a visual signal but also serves as a subtle behavioral cue: it encourages users—especially those distracted by their phones, to re-engage with their physical surroundings. At the same time, the illuminated signal communicates the user’s intended direction to nearby people, allowing them to proactively adjust their movements and interactions in response.</p>
				</div>
			</div>
		</section>

<!-- prototype section -->
		<section class="prototype-section" id="test">
			<h2 class="section-title">final prototype</h2>
			<div class="section-content">
				<div class="prototype-details1">
					<p class="text">The final prototype, whose fabrication process is detailed in the <a href="risorse/step/Final prototype.pdf" class="button full-report" target="_blank">final Prototype section</a> of the report, is a high-fidelity representation of the intended design. It was constructed using silicone, with an embedded interactive electronic circuit that powers the LED lights. To enhance its resemblance to a finished product, the entire form was covered with a fabric lining. The prototype’s core functionality and real-time responsiveness to user interaction enabled meaningful user testing, resulting in valuable insights.</p>	
					<img src="risorse/prototype_step1.png" class="prototype-image">				
				</div>
			</div>
		</section>

		

		<!-- exhibition section -->
		<section class="exhibition-section" id="redesign">
			<h2 class="section-title">Test, evaluations & final insights</h2>
			<div class="section-content">
				<div class="exhibition-details1">
					<p class="text">The final prototype was tested to assess whether the intended interaction was effectively conveyed through the design. In particular, the roleplaying research activity conducted during the earlier research phase was repeated with the same group of participants. This exercise yielded valuable insights into pedestrian behavior while walking. Further details and findings can be found in the <a href="risorse/step/Final prototype evaluation.pdf" class="button full-report" target="_blank">dedicated section</a> of the report.</p>

					<img src="risorse/finalinsights_step.png" alt="exhibition section" class="exhibition-image">

					<p class="text">Overall, the design can be considered successful in achieving its intended goal. By requiring active interaction, the device increases users' awareness of their surroundings and reduces their focus on their phones. Users reported feeling more communicative toward other pedestrians, even without receiving direct feedback, suggesting that the device effectively facilitates implicit social signaling. Its form, reminiscent of a video game controller, adds a playful and engaging dimension to the experience. Additionally, the device encourages users to be more mindful of their movements, leading to a straighter gait and more consistent walking pace, as observed during the role-playing activity. The product is particularly effective in communities that share common values and understand its intended use, emphasizing the need for cultural and contextual alignment to ensure its success. 
					</p>
				</div>
				<div class="exhibition-video-player">
					<video width="320" height="240" controls>
  <source src="risorse/step/DemoVideo.mp4" type="video/mp4">
  Your browser does not support the video tag.</video>

				</div>
			</div>
		</section>

<!-- recap -->
<section class="recap-section" id="recap">
	<div class="section-content">
		<div class="buttons">
			<a href="risorse/step/07_Cycle3Report-compresso.pdf" class="button full-report" target="_blank">View the full report</a>
		</div>
			<p class="text">Exploring Interaction - EI<br>
				2022<br>
				Delft University of Technology - TU Delft<br>
				Stefano delle Monache s.dellemonache@tudelft.nl - Project Supervisor<br>
 				Marise Schot marise@muzus.nl - Project Coordinator<br>
				Individual Project</p>				
		</div>
	</div>
</section>

<!-- Footer section -->
		<footer class="footer-section">
			<div class="section-content">
				<p class="copyright-text">© 2025 Laura Franco</p>


				<p class="policy-text">
					<a href="#" class="policy-link">Privacy policy</a>
					<!--<span class="separator">•</span>-->
				</p>
			</div>
		</footer>

	</main>


<script src="script.js"></script>
<script src="myscripts.js"></script>
</body>
</html>